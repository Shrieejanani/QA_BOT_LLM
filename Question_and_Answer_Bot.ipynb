{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs2bll9r9JiSzm36/trURF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shrieejanani/QA_BOT_LLM/blob/main/Question_and_Answer_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ5s2EkAIXi8"
      },
      "outputs": [],
      "source": [
        "#Installing Langchain package\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Proprietary LLM from -  Open AI"
      ],
      "metadata": {
        "id": "OF46kLHeNlrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing Openai package,which includes the classes that we can use to communicate with openai services\n",
        "!pip install Openai"
      ],
      "metadata": {
        "id": "iQ4r_oanNUAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports the python built-in module called \"os\"\n",
        "#This module provides a way to interact with the operating system such as ascessing environment variables working with files and directories,excecuting shells commands etc\n",
        "\n",
        "#The environ attribute is a dictionary-like object that contains the environment variables of the current operating session\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-WMuz9MDIkNzSvIWstYtMT3BlbkFJChnwcqqIsgZA47b8gZ1V\""
      ],
      "metadata": {
        "id": "C4npo_LgOF7f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#By accessing os.environ,we can retrive and manipulate environment variable within our python program.\n",
        "\n",
        "#For Example we can retrieve the value of a specific environment variable using the syntax os.environ[\"Variable_Name\"] where 'variablename' is the\n",
        "# name of the environment variable we want to access"
      ],
      "metadata": {
        "id": "rMkb_FkuRR-j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-openai"
      ],
      "metadata": {
        "id": "wJOOdRfyhw0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Langchain  has built a wrapper around Open APIs,using which we can  get access  to all the services Oen API Provides\n",
        "\n",
        "# Here We are initializing a language model object called  openAPI for our Natural language processing tasks\n",
        "\n",
        "from langchain_openai import OpenAI\n"
      ],
      "metadata": {
        "id": "ceHGKcyuS9fj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm  = OpenAI(model_name=\"gpt-3.5-turbo-instruct\",temperature=0)"
      ],
      "metadata": {
        "id": "h45NqwR2Ug0F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here Language model is represented by the object \"llm\" which is being utilized to generate a completion or response based on a specific query\n",
        "\n",
        "# The query stored in the \"our_query\" variable is being passed to the model through llm object\n",
        "\n",
        "our_query = \"capital of India?\"\n",
        "completion = llm.invoke(our_query)"
      ],
      "metadata": {
        "id": "Osf0T5kZcols"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion)"
      ],
      "metadata": {
        "id": "4CO3WPD4Vaab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa1494d-de8e-4003-8da5-478441229a56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "New Delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Capital of Tamilnadu?\"\n",
        "completio = llm.invoke(query)\n",
        "print(completio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqdM6q7P2xTW",
        "outputId": "56bf5149-5bef-4290-f850-e6274cdc4aa2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Chennai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Open-Source LLM hosted on Hugging Face"
      ],
      "metadata": {
        "id": "TcusnMbp3pfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "Be40S9q634l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = \"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\""
      ],
      "metadata": {
        "id": "Pcr_nq5k4Bay"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "MxF0kqot4onQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(repo_id = \"google/flan-t5-large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGIkoaAZ5J-9",
        "outputId": "bf81fe31-77b7-4f32-80c2-05db11113833"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The llm takes  a prompt as an input and outputs a completion\n",
        "our_q = \"What is the currency of india?\"\n",
        "complete = llm.invoke(our_q)\n"
      ],
      "metadata": {
        "id": "VsDj_GYF6A7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z1yGNPZp6_j7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}